#[version = "0.0.5"]
def @main(%conv2d_1_input: Tensor[(1, 1, 28, 28), float32] /* ty=Tensor[(1, 1, 28, 28), float32] */) -> Tensor[(1, 10), float32] {
  %0 = multiply(%conv2d_1_input, 16f /* ty=float32 */) /* ty=Tensor[(1, 1, 28, 28), float32] */;
  %1 = round(%0) /* ty=Tensor[(1, 1, 28, 28), float32] */;
  %2 = clip(%1, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 1, 28, 28), float32] */;
  %3 = cast(%2, dtype="int8") /* ty=Tensor[(1, 1, 28, 28), int8] */;
  %4 = nn.conv2d(%3, meta[relay.Constant][0] /* ty=Tensor[(6, 1, 3, 3), int8] */, padding=[1i64, 1i64, 1i64, 1i64], channels=6, kernel_size=[3, 3], out_dtype="int16") /* ty=Tensor[(1, 6, 28, 28), int16] */;
  %5 = add(%4, 64i16 /* ty=int16 */) /* ty=Tensor[(1, 6, 28, 28), int16] */;
  %6 = right_shift(%5, 7i16 /* ty=int16 */) /* ty=Tensor[(1, 6, 28, 28), int16] */;
  %7 = clip(%6, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 6, 28, 28), int16] */;
  %8 = cast(%7, dtype="int8") /* ty=Tensor[(1, 6, 28, 28), int8] */;
  %9 = annotation.stop_fusion(%8) /* ty=Tensor[(1, 6, 28, 28), int8] */;
  %10 = cast(%9, dtype="float32") /* ty=Tensor[(1, 6, 28, 28), float32] */;
  %11 = multiply(%10, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 6, 28, 28), float32] */;
  %12 = nn.bias_add(%11, meta[relay.Constant][1] /* ty=Tensor[(6), float32] */) /* ty=Tensor[(1, 6, 28, 28), float32] */;
  %13 = nn.relu(%12) /* ty=Tensor[(1, 6, 28, 28), float32] */;
  %14 = nn.avg_pool2d(%13, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %15 = multiply(%14, 16f /* ty=float32 */) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %16 = round(%15) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %17 = clip(%16, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %18 = cast(%17, dtype="int8") /* ty=Tensor[(1, 6, 14, 14), int8] */;
  %19 = nn.conv2d(%18, meta[relay.Constant][2] /* ty=Tensor[(16, 6, 3, 3), int8] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3], out_dtype="int16") /* ty=Tensor[(1, 16, 14, 14), int16] */;
  %20 = add(%19, 64i16 /* ty=int16 */) /* ty=Tensor[(1, 16, 14, 14), int16] */;
  %21 = right_shift(%20, 7i16 /* ty=int16 */) /* ty=Tensor[(1, 16, 14, 14), int16] */;
  %22 = clip(%21, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 14, 14), int16] */;
  %23 = cast(%22, dtype="int8") /* ty=Tensor[(1, 16, 14, 14), int8] */;
  %24 = annotation.stop_fusion(%23) /* ty=Tensor[(1, 16, 14, 14), int8] */;
  %25 = cast(%24, dtype="float32") /* ty=Tensor[(1, 16, 14, 14), float32] */;
  %26 = multiply(%25, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 16, 14, 14), float32] */;
  %27 = nn.bias_add(%26, meta[relay.Constant][3] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 14, 14), float32] */;
  %28 = nn.relu(%27) /* ty=Tensor[(1, 16, 14, 14), float32] */;
  %29 = nn.avg_pool2d(%28, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 16, 7, 7), float32] */;
  %30 = transpose(%29, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 7, 7, 16), float32] */;
  %31 = nn.batch_flatten(%30) /* ty=Tensor[(1, 784), float32] */;
  %32 = multiply(%31, 16f /* ty=float32 */) /* ty=Tensor[(1, 784), float32] */;
  %33 = round(%32) /* ty=Tensor[(1, 784), float32] */;
  %34 = clip(%33, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 784), float32] */;
  %35 = cast(%34, dtype="int8") /* ty=Tensor[(1, 784), int8] */;
  %36 = nn.dense(%35, meta[relay.Constant][4] /* ty=Tensor[(84, 784), int8] */, units=84, out_dtype="int16") /* ty=Tensor[(1, 84), int16] */;
  %37 = cast(%36, dtype="float32") /* ty=Tensor[(1, 84), float32] */;
  %38 = multiply(%37, 0.00012207f /* ty=float32 */) /* ty=Tensor[(1, 84), float32] */;
  %39 = nn.bias_add(%38, meta[relay.Constant][5] /* ty=Tensor[(84), float32] */) /* ty=Tensor[(1, 84), float32] */;
  %40 = nn.relu(%39) /* ty=Tensor[(1, 84), float32] */;
  %41 = multiply(%40, 16f /* ty=float32 */) /* ty=Tensor[(1, 84), float32] */;
  %42 = round(%41) /* ty=Tensor[(1, 84), float32] */;
  %43 = clip(%42, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 84), float32] */;
  %44 = cast(%43, dtype="int8") /* ty=Tensor[(1, 84), int8] */;
  %45 = nn.dense(%44, meta[relay.Constant][6] /* ty=Tensor[(10, 84), int8] */, units=10, out_dtype="int16") /* ty=Tensor[(1, 10), int16] */;
  %46 = cast(%45, dtype="float32") /* ty=Tensor[(1, 10), float32] */;
  %47 = multiply(%46, 0.000244141f /* ty=float32 */) /* ty=Tensor[(1, 10), float32] */;
  %48 = nn.bias_add(%47, meta[relay.Constant][7] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  nn.softmax(%48, axis=1) /* ty=Tensor[(1, 10), float32] */
}

/* For debugging purposes the metadata section has been omitted.
 * If you would like to see the full metadata section you can set the 
 * option to `True` when invoking `astext`. 
 */